{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5ba2fcd-81b4-4f77-9ea4-4bd0ca876071",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PROJET TECHNO DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e80422-4a5f-4d2b-a97b-f91893443d1b",
   "metadata": {},
   "source": [
    "## Auteurs\n",
    "\n",
    "Adrien Chaptal\n",
    "\n",
    "Gael Rousseau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01692ea-3219-461b-b2bb-0d15f79a849e",
   "metadata": {},
   "source": [
    "## Declaration librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721681a4-39e1-426d-97ad-8013313fed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# show plots in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df9451d-a89a-4da3-ae4a-bfcbbb276498",
   "metadata": {
    "tags": []
   },
   "source": [
    "## I - Analyse et Preparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c70db99-3e20-4a50-9049-147ef9a2cf3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "1. Etudier les données en affichants les informations correspondantes (colonnes, indice, etc) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c787e3-fbce-4495-84bd-0e3e4597e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO\n",
    "df_caracteristique = pd.read_csv('./bdd/caracteristiques-2017.csv', encoding ='latin1')\n",
    "print(df_caracteristique.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c78c27-1e42-4f65-8460-bc1c757e0bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lieux = pd.read_csv('./bdd/lieux-2017.csv', encoding ='latin1')\n",
    "\n",
    "print(df_lieux.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedcd54b-7d29-4869-825c-8b9c1f067cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usagers = pd.read_csv('./bdd/usagers-2017.csv', encoding ='latin1')\n",
    "\n",
    "print(df_usagers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386154de-c509-4e40-96fa-5e6810f3997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vehicules = pd.read_csv('./bdd/vehicules-2017.csv', encoding ='latin1')\n",
    "\n",
    "print(df_vehicules.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe73fdd-90a5-4efd-9388-b45d867d8724",
   "metadata": {},
   "source": [
    "2. Fusionner les fichiers de donnés "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56382c46-c813-417e-9ee4-b5cd73accc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136021, 55)\n"
     ]
    }
   ],
   "source": [
    "frames = [df_caracteristique, df_lieux, df_usagers, df_vehicules]\n",
    "df = pd.concat(frames, axis=1)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a01f98-fd97-40e6-b4ed-93419ad199cc",
   "metadata": {},
   "source": [
    "3. Nettoyer la base de données\n",
    "\n",
    "Ex : Identifier le pourcentage de valeurs NaN dans la base et éliminez les colonnes où la majorité\n",
    "des valeurs sont NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0e1e355-273b-4c6e-b87c-44f8d8bc2df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136021, 21)\n",
      "<bound method NDFrame.head of              Num_Acc  place  catu  grav  sexe  trajet  secu  locp  actp  \\\n",
      "0       201700000001    1.0     1     3     1     9.0  13.0   0.0   0.0   \n",
      "1       201700000001    2.0     2     3     2     9.0  11.0   0.0   0.0   \n",
      "2       201700000001    1.0     1     3     1     1.0  13.0   0.0   0.0   \n",
      "3       201700000002    1.0     1     1     1     0.0  11.0   0.0   0.0   \n",
      "4       201700000002    1.0     1     3     1     5.0  22.0   0.0   0.0   \n",
      "...              ...    ...   ...   ...   ...     ...   ...   ...   ...   \n",
      "136016  201700060699    1.0     1     1     2     9.0  11.0   0.0   0.0   \n",
      "136017  201700060700    1.0     1     1     2     9.0  11.0   0.0   0.0   \n",
      "136018  201700060700    1.0     1     4     1     9.0  21.0   0.0   0.0   \n",
      "136019  201700060700    2.0     2     4     2     9.0  21.0   0.0   0.0   \n",
      "136020  201700060701    1.0     1     4     1     1.0  21.0   0.0   0.0   \n",
      "\n",
      "        etatp  ...  num_veh       Num_Acc  senc  catv  occutc  obs  obsm  \\\n",
      "0         0.0  ...      B01  2.017000e+11   0.0   7.0     0.0  0.0   2.0   \n",
      "1         0.0  ...      B01  2.017000e+11   0.0  10.0     0.0  0.0   2.0   \n",
      "2         0.0  ...      A01  2.017000e+11   0.0   7.0     0.0  0.0   0.0   \n",
      "3         0.0  ...      A01  2.017000e+11   0.0   1.0     0.0  0.0   0.0   \n",
      "4         0.0  ...      B01  2.017000e+11   0.0  10.0     0.0  0.0   2.0   \n",
      "...       ...  ...      ...           ...   ...   ...     ...  ...   ...   \n",
      "136016    0.0  ...      B01           NaN   NaN   NaN     NaN  NaN   NaN   \n",
      "136017    0.0  ...      A01           NaN   NaN   NaN     NaN  NaN   NaN   \n",
      "136018    0.0  ...      B01           NaN   NaN   NaN     NaN  NaN   NaN   \n",
      "136019    0.0  ...      B01           NaN   NaN   NaN     NaN  NaN   NaN   \n",
      "136020    0.0  ...      A01           NaN   NaN   NaN     NaN  NaN   NaN   \n",
      "\n",
      "        choc  manv  num_veh  \n",
      "0        3.0   9.0      B01  \n",
      "1        3.0  13.0      A01  \n",
      "2        1.0  16.0      A01  \n",
      "3        7.0   1.0      B01  \n",
      "4        1.0   1.0      C01  \n",
      "...      ...   ...      ...  \n",
      "136016   NaN   NaN      NaN  \n",
      "136017   NaN   NaN      NaN  \n",
      "136018   NaN   NaN      NaN  \n",
      "136019   NaN   NaN      NaN  \n",
      "136020   NaN   NaN      NaN  \n",
      "\n",
      "[136021 rows x 21 columns]>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "qty_of_nuls = np.ceil(df.shape[1]/2)\n",
    "df.iloc[df[(df.isnull().sum(axis=1) >=qty_of_nuls)].index]\n",
    "\"\"\"\n",
    "\n",
    "df = df.loc[:, df.isnull().mean() < .5]\n",
    "print(df.shape)\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4157e8-543f-4428-8803-7bd30cfa2fa1",
   "metadata": {},
   "source": [
    "4. Supprimer les variables dont la majorité des observations sont manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dcb3008-d789-4edd-8583-b08538003001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_Acc    0\n",
      "Num_Acc    0\n",
      "dtype: int64\n",
      "Can't process Series...\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "29403\n",
      "0\n",
      "125194\n",
      "Removing column  0         0.0\n",
      "1         0.0\n",
      "2         0.0\n",
      "3         0.0\n",
      "4         0.0\n",
      "         ... \n",
      "136016    0.0\n",
      "136017    0.0\n",
      "136018    0.0\n",
      "136019    0.0\n",
      "136020    0.0\n",
      "Name: locp, Length: 136021, dtype: float64\n",
      "124717\n",
      "Removing column  0         0.0\n",
      "1         0.0\n",
      "2         0.0\n",
      "3         0.0\n",
      "4         0.0\n",
      "         ... \n",
      "136016    0.0\n",
      "136017    0.0\n",
      "136018    0.0\n",
      "136019    0.0\n",
      "136020    0.0\n",
      "Name: actp, Length: 136021, dtype: float64\n",
      "124680\n",
      "Removing column  0         0.0\n",
      "1         0.0\n",
      "2         0.0\n",
      "3         0.0\n",
      "4         0.0\n",
      "         ... \n",
      "136016    0.0\n",
      "136017    0.0\n",
      "136018    0.0\n",
      "136019    0.0\n",
      "136020    0.0\n",
      "Name: etatp, Length: 136021, dtype: float64\n",
      "0\n",
      "num_veh    0\n",
      "num_veh    0\n",
      "dtype: int64\n",
      "Can't process Series...\n",
      "Num_Acc    0\n",
      "Num_Acc    0\n",
      "dtype: int64\n",
      "Can't process Series...\n",
      "18652\n",
      "0\n",
      "102968\n",
      "Removing column  0         0.0\n",
      "1         0.0\n",
      "2         0.0\n",
      "3         0.0\n",
      "4         0.0\n",
      "         ... \n",
      "136016    NaN\n",
      "136017    NaN\n",
      "136018    NaN\n",
      "136019    NaN\n",
      "136020    NaN\n",
      "Name: occutc, Length: 136021, dtype: float64\n",
      "88644\n",
      "Removing column  0         0.0\n",
      "1         0.0\n",
      "2         0.0\n",
      "3         0.0\n",
      "4         0.0\n",
      "         ... \n",
      "136016    NaN\n",
      "136017    NaN\n",
      "136018    NaN\n",
      "136019    NaN\n",
      "136020    NaN\n",
      "Name: obs, Length: 136021, dtype: float64\n",
      "18483\n",
      "6702\n",
      "7602\n",
      "num_veh    0\n",
      "num_veh    0\n",
      "dtype: int64\n",
      "Can't process Series...\n"
     ]
    }
   ],
   "source": [
    "# Count number of zeros in all columns of Dataframe\n",
    "for column_name in df.columns:\n",
    "    shape= df.shape[0]\n",
    "    column = df[column_name]\n",
    "    # Get the count of Zeros in column \n",
    "    count = (column == 0).sum()\n",
    "    print(count);\n",
    "    pct=count/shape\n",
    "    if(isinstance(pct, pd.Series)):\n",
    "        print(\"Can't process Series...\")\n",
    "    elif(pct > 0.5):\n",
    "        df.drop([column_name], axis=1, inplace=True)\n",
    "        print(\"Removing column \", column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08aebc4-ccf4-45ad-8100-a5d3570b0f0e",
   "metadata": {},
   "source": [
    "5. Remplir les valeurs NaN par différentes méthodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7298fcc-a803-4d81-89f2-909b42520370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_Acc        0\n",
      "place      11802\n",
      "catu           0\n",
      "grav           0\n",
      "sexe           0\n",
      "trajet        11\n",
      "secu        8950\n",
      "an_nais       37\n",
      "num_veh        0\n",
      "Num_Acc    32475\n",
      "senc       32543\n",
      "catv       32475\n",
      "obsm       32517\n",
      "choc       32510\n",
      "manv       32505\n",
      "num_veh    32475\n",
      "dtype: int64\n",
      "248300\n",
      "0\n",
      "Num_Acc    0\n",
      "place      0\n",
      "catu       0\n",
      "grav       0\n",
      "sexe       0\n",
      "trajet     0\n",
      "secu       0\n",
      "an_nais    0\n",
      "num_veh    0\n",
      "Num_Acc    0\n",
      "senc       0\n",
      "catv       0\n",
      "obsm       0\n",
      "choc       0\n",
      "manv       0\n",
      "num_veh    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def fill_nas_by_type(df, col_name):\n",
    "    \"\"\"Fill null values in df according to col_name type\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : dataframe, (default=None)\n",
    "        input dataframe\n",
    "    col_name : str, (default=None)\n",
    "        column with null values to fill\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    df with filled values in col_name\n",
    "    \"\"\"\n",
    "    if (col_name == \"trajet\"):\n",
    "        df[col_name] = df[col_name].fillna(value=9)\n",
    "    elif (col_name == \"place\"):\n",
    "        df[col_name] = df[col_name].fillna(df[col_name].value_counts()[:1].index.tolist()[0])\n",
    "    elif (col_name == \"an_nais\"):\n",
    "        df[col_name] = df[col_name].fillna(float(df[col_name].median()))\n",
    "    elif (col_name == \"catv\"):\n",
    "        df[col_name] = df[col_name].fillna(value=99)\n",
    "    elif (col_name == \"obsm\"):\n",
    "        df[col_name] = df[col_name].fillna(value=99)\n",
    "    elif (col_name == \"choc\"):\n",
    "        df[col_name] = df[col_name].fillna(value=9)\n",
    "    elif (col_name == \"manv\"):\n",
    "        df[col_name] = df[col_name].fillna(value=25)\n",
    "    elif (col_name == \"senc\"):\n",
    "        df[col_name] = df[col_name].fillna(df[col_name].value_counts()[:1].index.tolist()[0])\n",
    "    elif (col_name == \"num_veh\"):\n",
    "        df[col_name] = df[col_name].iloc[:, 0].fillna(pd.Series(np.random.choice(['A01', 'B01', 'C01'], p=[0.52, 0.30, 0.18], size=len(df))))\n",
    "        df[col_name] = df[col_name].iloc[:, 1].fillna(pd.Series(np.random.choice(['A01', 'B01', 'C01'], p=[0.52, 0.30, 0.18], size=len(df))))\n",
    "    elif (col_name == \"Num_Acc\"):\n",
    "        df[col_name] = df[col_name].fillna(method='ffill')\n",
    "    elif (col_name == \"secu\"):\n",
    "        df[col_name] = df[col_name].fillna(df[col_name].value_counts()[:1].index.tolist()[0])\n",
    "    return df\n",
    "\n",
    "cols_to_fill = list(df.columns)\n",
    "\n",
    "print(df.isnull().sum(axis = 0))\n",
    "\n",
    "print(df.isnull().sum().sum())\n",
    "for x in cols_to_fill:\n",
    "    df = fill_nas_by_type(df, x)\n",
    "print(df.isnull().sum().sum())\n",
    "print(df.isnull().sum(axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60f6098-892c-427d-bbab-47eb8cc14f91",
   "metadata": {},
   "source": [
    "6. Analyser les données par les statistiques (min, max, médiane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f269676-c715-4fe3-9f7b-3caa66a60860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: place\n",
      "count    136021.000000\n",
      "mean          1.393300\n",
      "std           1.233188\n",
      "min           1.000000\n",
      "25%           1.000000\n",
      "50%           1.000000\n",
      "75%           1.000000\n",
      "max           9.000000\n",
      "Name: place, dtype: float64\n",
      "\n",
      " \n",
      "\n",
      "Column: catu\n",
      "count    136021.000000\n",
      "mean          1.349814\n",
      "std           0.639996\n",
      "min           1.000000\n",
      "25%           1.000000\n",
      "50%           1.000000\n",
      "75%           2.000000\n",
      "max           4.000000\n",
      "Name: catu, dtype: float64\n",
      "\n",
      " \n",
      "\n",
      "Column: grav\n",
      "count    136021.000000\n",
      "mean          2.492858\n",
      "std           1.330687\n",
      "min           1.000000\n",
      "25%           1.000000\n",
      "50%           3.000000\n",
      "75%           4.000000\n",
      "max           4.000000\n",
      "Name: grav, dtype: float64\n",
      "\n",
      " \n",
      "\n",
      "Column: sexe\n",
      "count    136021.000000\n",
      "mean          1.323016\n",
      "std           0.467631\n",
      "min           1.000000\n",
      "25%           1.000000\n",
      "50%           1.000000\n",
      "75%           2.000000\n",
      "max           2.000000\n",
      "Name: sexe, dtype: float64\n",
      "\n",
      " \n",
      "\n",
      "Column: trajet\n",
      "count    136021.000000\n",
      "mean          3.476713\n",
      "std           2.647390\n",
      "min           0.000000\n",
      "25%           1.000000\n",
      "50%           4.000000\n",
      "75%           5.000000\n",
      "max           9.000000\n",
      "Name: trajet, dtype: float64\n",
      "\n",
      " \n",
      "\n",
      "Column: secu\n",
      "count    136021.000000\n",
      "mean         17.393175\n",
      "std          17.277594\n",
      "min           1.000000\n",
      "25%          11.000000\n",
      "50%          11.000000\n",
      "75%          21.000000\n",
      "max          93.000000\n",
      "Name: secu, dtype: float64\n",
      "\n",
      " \n",
      "\n",
      "Column: an_nais\n",
      "count    136021.000000\n",
      "mean       1978.317797\n",
      "std          18.883170\n",
      "min        1914.000000\n",
      "25%        1965.000000\n",
      "50%        1982.000000\n",
      "75%        1993.000000\n",
      "max        2017.000000\n",
      "Name: an_nais, dtype: float64\n",
      "\n",
      " \n",
      "\n",
      "Column: num_veh\n",
      "       num_veh num_veh\n",
      "count   136021  136021\n",
      "unique      39      39\n",
      "top        A01     A01\n",
      "freq     82513   82513\n",
      "\n",
      " \n",
      "\n",
      "Column: senc\n",
      "count    136021.000000\n",
      "mean          1.114401\n",
      "std           0.612836\n",
      "min           0.000000\n",
      "25%           1.000000\n",
      "50%           1.000000\n",
      "75%           2.000000\n",
      "max           2.000000\n",
      "Name: senc, dtype: float64\n",
      "\n",
      " \n",
      "\n",
      "Column: catv\n",
      "count    136021.000000\n",
      "mean         32.817205\n",
      "std          38.390817\n",
      "min           1.000000\n",
      "25%           7.000000\n",
      "50%           7.000000\n",
      "75%          36.000000\n",
      "max          99.000000\n",
      "Name: catv, dtype: float64\n",
      "\n",
      " \n",
      "\n",
      "Column: obsm\n",
      "count    136021.000000\n",
      "mean         24.930540\n",
      "std          41.530365\n",
      "min           0.000000\n",
      "25%           2.000000\n",
      "50%           2.000000\n",
      "75%           9.000000\n",
      "max          99.000000\n",
      "Name: obsm, dtype: float64\n",
      "\n",
      " \n",
      "\n",
      "Column: choc\n",
      "count    136021.000000\n",
      "mean          4.377677\n",
      "std           3.353667\n",
      "min           0.000000\n",
      "25%           1.000000\n",
      "50%           3.000000\n",
      "75%           9.000000\n",
      "max           9.000000\n",
      "Name: choc, dtype: float64\n",
      "\n",
      " \n",
      "\n",
      "Column: manv\n",
      "count    136021.000000\n",
      "mean         10.862845\n",
      "std          10.156319\n",
      "min           0.000000\n",
      "25%           1.000000\n",
      "50%           9.000000\n",
      "75%          23.000000\n",
      "max          25.000000\n",
      "Name: manv, dtype: float64\n",
      "\n",
      " \n",
      "\n",
      "Column: num_veh\n",
      "       num_veh num_veh\n",
      "count   136021  136021\n",
      "unique      39      39\n",
      "top        A01     A01\n",
      "freq     82513   82513\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## TO DO\n",
    "\n",
    "for col_name in df.columns:\n",
    "    \n",
    "    if(col_name != \"Num_Acc\"):\n",
    "        print(\"Column: \" + col_name)\n",
    "\n",
    "        print(df[col_name].describe())\n",
    "        print(\"\\n \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dcddf0-1b40-404f-a2b5-68e1816bec31",
   "metadata": {},
   "source": [
    "7. Expliquer la gravité des accidents en fonction des autres variables (créer une nouvelle variable \"mortalité\" qui indique si la victime est décédée ou non suite à l'accident : tué=1 non=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a0c4ed9-f654-4858-b583-a3ec0db0a3e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21204/3110475618.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrav\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mortalite'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mtue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNaN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1535\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1537\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1538\u001b[0m             \u001b[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1539\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "tue = df.grav == 2\n",
    "\n",
    "df['mortalite'] = np.where(tue, 1, np.where(np.logical_not(tue), 0, np.NaN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728c60f6-7342-42cb-be0d-dc63f831e2d3",
   "metadata": {},
   "source": [
    "## II - Visualisation et modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5412b25d-babe-4a56-b430-f748cf24cf49",
   "metadata": {},
   "source": [
    "1. Mettre en place les modèles de machine learning pour prédire et classifier la mortalité : Régression logistique, Decision Tree, Random Forest, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f225aa-3c90-4ae8-8d44-5a2a8e102f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9d3762-d026-4421-bca7-21ef94653fcc",
   "metadata": {},
   "source": [
    "2. Visualiser et expliquer la distribution de la variable 'mortalité' selon les différentes variables (le genre des victimes, l'Age, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a800d4b8-571d-4213-8127-4c2daa2c0b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09346b6f-5304-4a7d-833a-952e35bf19b0",
   "metadata": {},
   "source": [
    "3. Normaliser les données et les appliquer aux modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f82c9f1-13d5-4c4d-9f6b-934790203eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bb6620-7c05-428a-9591-ff097c5fdb01",
   "metadata": {},
   "source": [
    "4. Analyser, visualiser et expliquer le niveau de corrélation entre les variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3944275-1713-4f74-a579-ffc54e1455df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3fa450-0c1f-46c4-8517-7e5c9a5cfc9f",
   "metadata": {},
   "source": [
    "5. Analyser à la base du temps : Nombre d'accidents en années, Nombre d'accidents en mois, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caef3999-c324-41d8-a91e-f1baa176c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cb4ea1-759f-4498-81ad-60dd8143870d",
   "metadata": {},
   "source": [
    "6. Trouver l’heure de la journée la plus dangereuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d38d536-d156-4a66-8407-a7c86a6649d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9272a393-d0cd-40c1-b2d2-36866f942d97",
   "metadata": {},
   "source": [
    "## III - Comparaison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1699bb4-da3e-45e0-9662-b501db46e781",
   "metadata": {},
   "source": [
    "1. Faire la comparaison entre les modèles avec les données originales et normalisé par rapport aux différentes métriques : MSE, MAE, Score, Précision, Matrice de confusion etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb97f8f-ec96-400c-8f07-0bc562ed0139",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab395e57-6551-4183-b5b7-358a863cf011",
   "metadata": {},
   "source": [
    "2. Faire la comparaison entre toutes les modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24666ba0-fdf1-497e-840d-7cf927e981d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a939a41-e103-4172-9e92-fa0ca2cf2f39",
   "metadata": {},
   "source": [
    "3. Faire la comparaison entre les méthodes train-test-split et la validation croisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0206dd-1439-461e-9ed9-1eb96c86949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db54624-84fb-4a35-9d75-a0ebe8b36b3f",
   "metadata": {},
   "source": [
    "4. Trouver les meilleur paramètres à l’aide de GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52be8a17-dd0e-4557-9bb4-d1247a9e5151",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57b51b7-d1b3-47a5-a18a-2090c8d67a89",
   "metadata": {},
   "source": [
    "## IV - Amélioration des performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c06282-a6a8-4aa6-bc4d-9b62672e0c43",
   "metadata": {},
   "source": [
    "1. Améliorer les performances des modèles : ajouter des nouvelles variables, régulariser les modèles, utiliser les modèles d'ensemble, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1d936-5757-4d3c-8177-a6e0be339260",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
